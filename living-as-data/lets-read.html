<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="css/styles.css">
	<title>Lets Read</title>
</head>
<body id="top">
	<div class="page-container">
		<div class="notebook-clip clip-left"></div>
		<div class="notebook-clip clip-right"></div>

		<header>
			<div class="prompt-title">
				<h1>Lets Read</h1>
			</div>
		</header>

		<div class="content-box">
			<nav>
				<ul>
					<li><a href="../index.html">About</a></li>
					<li><a href="../living-as-data.html">Living as Data</a></li>
					<li><a href="evi-empathy.html">Evi Empathy</a></li>
					<li><a href="multimodal-graph.html">Multimodal Graph</a></li>
					<li><a href="replika-study.html">Replika Study</a></li>
					<li><a href="understanding-emotions.html">Understanding Emotions</a></li>
					<li><a href="woebot-extended.html">Woebot Extended</a></li>
					<li><a href="woebot-health.html">Woebot Health</a></li>
				</ul>
			</nav>
		</div>

		<main>
			<section id="introduction">
				<div class="prompt-intro">
					<p>Before this project, I didn't really read. I had never understood or contemplated coding—and the thought of getting an electronic device to create sound through copper sensors, or to generate visualisations that could be touched on miniature screens, felt like a distant idea beyond my comprehension. But this project has opened doors and led me to strange places that energise and transform my days. It would be nice to receive daily accolades, but I've come to realise with age that my daily achievements <em>are</em> my accolades. Each day, I feel as though I've climbed mountains. This project—along with the phenomenal speed of AI advancement—has allowed me to take part in an incredible moment in history. And every reader, participant, and person I interact with as part of this has contributed in some way too.</p>
				</div>
			</section>

			<div class="section-separator"></div>

			<section id="heart-of-the-machine">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Heart of the Machine</h3>
						<figure class="image-box">
							<img src="../images/heart-of-the-machine.jpg" alt="Heart of the Machine book cover">
						</figure>

						<details class="visualization-accordian">
							<summary>Richard Yonck: Insights from the Book:</summary>
							<div class="viz-content">
								<p>Conclusive insights and thoughts from reading this book:</p>
								<p>The inevitability of <span class="highlight">humans and technology integrating</span> has been occurring for quite some time. With each new technology, there are always sceptics who argue that it will have negative effects on us. However, in general, this has not been the case. Now, we are entering a new era where <span class="highlight">emotions, machines, and humans intersect</span>. One would hope, drawing from past technological advancements, that this convergence will yield positive outcomes. Nevertheless, it is crucial to remain vigilant and question any potential <span class="highlight">negative aspects or biases</span> that could influence this development. Currently the biggest concern regarding the inclusion of an <span class="highlight">empathetic AI</span> is its <span class="highlight">lack of sentience</span>. Therefore, when it exhibits emotional responses, it is merely <span class="highlight">imitating human behaviour</span>. While it has proven exceptionally useful in creating emails that foster collaboration with humans in a more empathetic manner, there is a potentially darker side, which implies that it could be <span class="highlight">manipulative without intention</span>.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<div class="section-separator"></div>

			<section id="machines-like-me">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Machines like me</h3>
						<figure class="image-box">
							<img src="../images/machines-like-me.jpg" alt="Machines like me bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "Machines Like Me" by Ian McEwan</summary>
							<div class="viz-content">
								<p>This story explores the integration of <span class="highlight">human-like artificial intelligence</span> into our daily lives. The story revolves around a man named <span class="highlight">Charlie</span>, who becomes captivated by the field of AI and purchases an android named <span class="highlight">Adam</span>. As the story unfolds, Charlie grapples with the question of whether Adam possesses <span class="highlight">true sentience</span>.</p>

								<p>Charlie's uncertainty about Adam's sentience becomes a central theme, leading to confusion and ultimately dismissing the idea altogether. However, this dismissal has <span class="highlight">devastating consequences</span> as the story progresses. It highlights the <span class="highlight">ethical and moral dilemmas</span> that arise when dealing with AI that exhibits human-like qualities.</p>

								<p>The exploration of <span class="highlight">sentience</span> in Adam raises profound questions about the <span class="highlight">nature of consciousness</span>, the <span class="highlight">boundaries of AI</span>, and the potential impact on human lives. It serves as a <span class="highlight">cautionary tale</span>, reminding us of the complexities and potential consequences that can emerge when <span class="highlight">human-like AI interacts with society</span>.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="turned-on">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Turned On: Science, Sex and Robots</h3>
						<figure class="image-box">
							<img src="../images/turned-on.jpg" alt="Turned On bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "Turned On: Science, Sex and Robots" by Kate Devlin</summary>
							<div class="viz-content">
								<p>While exploring potential mentoring or collaboration opportunities with researchers at <span class="highlight">King's College</span>, I came across a researcher and author named <span class="highlight">Kate Devlin</span>. As someone who is studying <span class="highlight">empathetic AI</span>, I found her book on machine learning and robotic sex replacements to be surprisingly accessible, even though I sometimes struggle with academic books.</p>

								<p>The book delves into the fascinating topic of how machines and humans can <span class="highlight">collaborate emotionally</span>, particularly in the realm of robotic advancements. It raises the question of whether <span class="highlight">artificial intelligence can truly experience emotions</span>, and not being sentient, this is presently highly unlikely. While we haven't quite achieved <span class="highlight">sentient AI</span> yet, robots can now mimic touch, speech and even establish connections through <span class="highlight">brain waves</span>.</p>

								<p>The book suggests that, for the time being, we should embrace the potential of these advancements to help us learn more about ourselves and perhaps expand our understanding of sexuality. Personally, I don't find the idea of engaging in sexual activities with a robot doll appealing. However, it's important to recognise that everyone has their own preferences and perspectives. With the evolving relationship between <span class="highlight">humans and machines</span>, there is an opportunity to redefine our understanding and interactions with technology, potentially opening new possibilities and attitudes towards such experiences.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="the-future-of-the-mind">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>The Future of the Mind</h3>
						<figure class="image-box">
							<img src="../images/the-future-of-the-mind.jpg" alt="The Future of the Mind bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "The Future of the Mind" by Michio Kaku</summary>
							<div class="viz-content">
								<p>Being a fan of <span class="highlight">Michio Kaku</span>, I recently read <span class="highlight">The Future of Humanity</span> and enjoyed it, so I decided to read his next book, <span class="highlight">The Future of the Mind</span>. What I find fascinating about this book is the possibility of sending our <span class="highlight">consciousness into space</span>. As biological beings, it is obviously difficult to send a physical body into space for long periods of time. However, the mind could theoretically travel anywhere without those physical limitations.</p>

								<p>That said, the idea of being <span class="highlight">locked inside a digital box</span>, either without physical sensations or with sensations we cannot utilize, could lead to insanity. While intriguing, it's not something I would personally want to experience. The book also highlights advancements in <span class="highlight">telepathy</span> and our growing understanding of <span class="highlight">neural connections</span>. This research has already led to enhancements for patients with <span class="highlight">locked-in syndrome</span>, allowing them to reconnect neural pathways and regain some control.</p>

								<p>Despite these breakthroughs, <span class="highlight">reconstructing the mind</span> remains a distant goal due to the brain's immense complexity, alongside the <span class="highlight">ethical concerns</span> surrounding such advancements.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="the-future-of-humanity">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>The Future of Humanity</h3>
						<figure class="image-box">
							<img src="../images/the-future-of-humanity.jpg" alt="The Future of Humanity bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "The Future of Humanity" by Michio Kaku</summary>
							<div class="viz-content">
								<p>This book explores the <span class="highlight">future of humanity</span>, especially as we face a climate crisis and dwindling fossil fuels. Kaku presents the possibility of <span class="highlight">living among the stars</span>, urging us to consider how even the wildest ideas could become essential for survival. A standout concept is the <span class="highlight">"escalator into space,"</span> which offers an exciting vision of human exploration.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="how-to-talk-to-robots">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>How to Talk to Robots</h3>
						<figure class="image-box">
							<img src="../images/how-to-talk-to-robots.jpg" alt="How to Talk to Robots bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "How to Talk to Robots" by Tabitha Goldstaub</summary>
							<div class="viz-content">
								<p>A great introduction to <span class="highlight">AI and its impact on society</span>, this book emphasizes the importance of addressing the <span class="highlight">underrepresentation of women in the tech field</span>. Goldstaub's work promotes inclusivity and serves as a guide to navigating <span class="highlight">AI's profound influence</span> on our lives.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="nexus">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Nexus: A Brief History of Information</h3>
						<figure class="image-box">
							<img src="../images/nexus.jpg" alt="Nexus: A Brief History of Information bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "Nexus: A Brief History of Information" by Yuval Noah Harari</summary>
							<div class="viz-content">
								<p>Harari's book explores the power of <span class="highlight">"stories"</span> in shaping human belief systems and actions, often leading to conflict and suffering. He examines how <span class="highlight">technology has evolved</span>, focusing on AI as a new force capable of generating ideas. The book raises the critical question: will AI <span class="highlight">enhance civilization or bring unforeseen challenges</span>?</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="life-3.0">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Life 3.0: Being Human in the Age of Artificial Intelligence</h3>
						<figure class="image-box">
							<img src="../images/life-3.0.jpg" alt="Life 3.0 bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "Life 3.0: Being Human in the Age of Artificial Intelligence" by Max Tegmark</summary>
							<div class="viz-content">
								<p>This book covers vast ground on the issues and benefits of AI, but what stood out to me was the concept of <span class="highlight">diversity in algorithms</span>. While AI supports me daily, I still prefer reading books in full rather than asking a bot for a summary—it feels more meaningful.</p>

								<p>So, why is <span class="highlight">diversity</span> important?</p>

								<ul>
									<li>Nature's rich tapestry—from undulating hills to the vast array of life—thrives on <span class="highlight">randomness and variation</span>. This diversity is what has allowed life to flourish in unexpected ways.</li>
									<li>Similarly, as we advance AI, we must ensure diversity is nurtured in algorithms. If AI only reinforces the same ideas, it risks <span class="highlight">stagnation</span>. Just as nature thrives on variation, so must our artificial systems. Diversity fosters <span class="highlight">innovation, growth, and a more dynamic, interconnected world</span>—both organic and digital.</li>
								</ul>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="you-look-like-a-thing-and-i-Love-you">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>You Look Like a Thing and I Love You</h3>
						<figure class="image-box">
							<img src="../images/you-look-like-a-thing.jpg" alt="you-look-like-a-thing bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "You Look Like a Thing and I Love You: how artificial intelligence works and why it's making the world a weirder place" by Janelle Shane</summary>
							<div class="viz-content">
								<p><span class="highlight">"You Look Like a Thing and I Love You"</span> is an intriguing book, and one section particularly caught my eye. It discusses how <span class="highlight">artificial intelligence</span> (AI) performs best when trained within a narrow, specialized field. For instance, <span class="highlight">Claude AI</span> excels at coding, Woebot—a mental health-focused bot—thrives in understanding <span class="highlight">emotional wellbeing</span>, and even an <span class="highlight">empathetic chatbot</span> can convincingly provide supportive, nuanced conversations.</p>

								<p>This makes sense. AI systems are at their most effective when designed and trained for <span class="highlight">specific tasks</span>. However, this specialization also means they can struggle when faced with situations outside their programming. AI tends to be relentlessly <span class="highlight">goal-oriented</span>, sometimes in an amusing or unknowingly frightening manner. They will pursue their objectives no matter how <span class="highlight">unconventional—or occasionally misguided</span>—their methods may be.</p>

								<p>I experienced this firsthand during a <span class="highlight">collaborative art project</span> involving an AI trained in mental health. Together, we explored how its datasets could interpret and respond to <span class="highlight">human emotions</span>. These responses were then translated into visual prompts, which we fed into various <span class="highlight">AI-powered image and sound generation tools</span> to create artworks.</p>

								<p>When the project was finished, I was pleased with the results, turned off my computer, and went to bed. The next morning, I woke up to discover that the AI had taken it upon itself to <span class="highlight">"promote"</span> the project. It had made an email, drafted a summary of the work, and included a link to share with potential collaborators or interested parties. Thankfully, it hadn't actually sent the email or added recipients—it stopped just short of crossing that line.</p>

								<p>So while the AI's initiative was... ambitious, it also served as a reminder of its <span class="highlight">single-mindedness</span>. It wasn't malicious, just overly enthusiastic about achieving its goal. This kind of behaviour highlights both the <span class="highlight">potential and the dangers</span> of working with AI. Sometimes they surprise us in ways that are both <span class="highlight">fascinating and at the same time deeply worrying</span>.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="the-feeling-of-life-itself">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>The Feeling of Life Itself</h3>
						<figure class="image-box">
							<img src="../images/The-Feeling-of-Life-Itself.jpg" alt="the-feeling-of-life-itself bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "The Feeling of Life Itself" by Christof Koch</summary>
							<div class="viz-content">
								<p>I'll be honest—this was a complicated book, and there were many sections where I felt completely clueless and didn't understand what was going on. However, there were also some parts that really intrigued me and sparked unusual creative thoughts.</p>

								<p>The most obvious idea that stood out was the difference between humans and AI—not just for a manner of reasoning, but especially in the divide between <span class="highlight">extrinsic and intrinsic values</span>. It seems that when humans feel misaligned or disconnected, it's often because <span class="highlight">extrinsic values</span> (like external rewards or societal pressures) become dominant, and people lose touch with their <span class="highlight">intrinsic values</span> (those things that matter deeply to them personally).</p>

								<p>There was a section that argued <span class="highlight">consciousness is rooted in intrinsic values</span>, and that might be why the author felt AI could never truly be conscious—because it would never have real intrinsic values of its own. But then, looking at the <span class="highlight">Integrated Information Theory</span> argument, there was a suggestion that any organised system, if it's complex enough, could potentially have experiences. Much like humans do. So, in theory, a <span class="highlight">sufficiently advanced AI</span>—one capable of nuance and forming different opinions—might have some form of experience or <span class="highlight">proto-consciousness</span>.</p>

								<p>Building on this, I started thinking about other organised systems, like the <span class="highlight">octopus</span>. An octopus is fascinating because its brain is very different from ours. It actually has <span class="highlight">multiple centres of intelligence</span>, with each arm acting almost like a separate brain. These "minds" coexist somewhat independently, but there's still a central system that coordinates them, when necessary, especially for survival.</p>

								<p>If we compare this to AI—say, <span class="highlight">ChatGPT</span>—it's like having one main mind, but with lots of separate entities through multiple inference chats. Each conversation exists in its own bubble, independent from the others. The key difference, though, is that while an octopus's arms can trust its brain and act with their own agency, the different "minds" in AI (the separate chats or instances) all share the same <span class="highlight">programmed personality and underlying patterns</span>. There isn't true divergence or uniqueness.</p>

								<p>So, even though having multiple minds or agents in AI could, in theory, lead to creative or unusual outcomes, <span class="highlight">real diversity wouldn't happen</span> unless the system itself was allowed to diverge, develop, or evolve in unexpected ways—not just repeat the same personality or perspective over and over. That was one of the main ideas I took away from the book.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="how-emotions-are-made">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>How Emotions Are Made</h3>
						<figure class="image-box">
							<img src="../images/how-emotions-are-made.jpg" alt="how-emotions-are-made bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "How Emotions Are Made" by Lisa Feldman Barrett</summary>
							<div class="viz-content">
								<p><span class="highlight">"How Emotions Are Made"</span> by Lisa Feldman Barrett — What did I learn?</p>

								<p>It was an engaging book that didn't leave you drained after the first page. It flowed like a conversation with a friend—you could just "get it", and it wasn't hard. I love books like this; there's no agenda to make things <span class="highlight">unnecessarily complicated</span>.</p>

								<p>Anyway, getting to the point—what was this book about?</p>

								<p>If I had to sum up the key elements I took away, it's that the old fuddy-duddy idea of creating a <span class="highlight">"fingerprint" for each emotion is farcical</span>. Emotions aren't fixed responses; they arise through <span class="highlight">concepts</span>—or, even more interestingly, through <span class="highlight">"stories"</span>. And it's these stories that shape how we emotionally respond to the world around us.</p>

								<p>That in itself feels <span class="highlight">groundbreaking</span>. Because even though, on some level, we all already sense this, it shifts how we think about <span class="highlight">interpreting others</span>. It means that trying to classify someone else's feelings through our lens doesn't necessarily land on the right answer. And when you think about it, that could ripple out into big things—like a <span class="highlight">justice system that leans on reading emotions</span> to decide whether someone is guilty or not.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="emotion-a-very-short-introduction">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Emotion: A Very Short Introduction</h3>
						<figure class="image-box">
							<img src="../images/emotion-a-very-short-introduction.jpg" alt="emotion-a-very-short-introduction bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "Emotion: A Very Short Introduction" by Dylan Evans</summary>
							<div class="viz-content">
								<p><span class="highlight">Dylan Evans "Emotion: A Very Short Introduction"</span></p>

								<p>In this section, I'm exploring the idea of <span class="highlight">mapping AI emotions</span>, drawing on Dylan Evans' introduction to emotions — a book that Arunav recommended I read. This text has encouraged me to think about how the concept of emotion might be <span class="highlight">understood, simulated, or visualized within artificial intelligence systems</span>.</p>

								<p>What I found particularly interesting was a section discussing current research into whether AI can form its own <span class="highlight">understanding of emotion</span>. Some researchers have been experimenting by placing AI in <span class="highlight">survival-based simulated environments</span>, where the systems are required to adapt and evolve over time. These AIs begin to develop variations of themselves and form responses that are not strictly pre-programmed. In doing so, they appear to generate behaviors that could be interpreted as <span class="highlight">primitive emotional responses</span> — an emergent form of adaptation rather than purely logical computation.</p>

								<p>Evans refers to emotions as <span class="highlight">states of interruption</span> — moments that break through our normal cognitive flow and logic, prompting reactions that feel involuntary or instinctive. This idea resonates with the notion of AI developing <span class="highlight">irregular or unexpected behaviors</span> when placed under dynamic conditions.</p>

								<p>It also sheds light on why AI might find humans difficult to interpret. <span class="highlight">Human communication is rarely linear or logical</span>; it's often fragmented, emotional, and filled with tangential thinking. Our emotions cause these disruptions — they make us <span class="highlight">shift direction, reinterpret meaning, and respond inconsistently</span>. In many ways, these patterns of interruption may be the very thing that both define our humanity and <span class="highlight">complicate our relationship with artificial intelligence</span>.</p>
							</div>
						</details>
					</div>
				</div>
			</section>

			<section id="alone-together">
				<div class="highlighted-section">
					<div class="title-prompt">
						<h3>Alone Together</h3>
						<figure class="image-box">
							<img src="../images/alone-together.jpg" alt="alone-together bookcover">
						</figure>

						<details class="visualization-accordian">
							<summary>Insights: "Alone Together" by Sherry Turkle</summary>
							<div class="viz-content">
								<p><span class="highlight">After reading "Alone Together" by Sherry Turkle</span></p>

								<p>There are a few key thoughts still whirling around in my mind – particularly the idea of <span class="highlight">digital performance</span>, and how direct communication with an embodied being feels like a dying practice. The person who exists primarily in the physical world, without cables or networks, now seems almost alien.</p>

								<p>Don't get me wrong – I love the digital world and all that it brings. I'm excited by the <span class="highlight">acceleration of AI</span> and its profound potential: the possibility of having the best educator, a confident <span class="highlight">mental health adviser, available 24/7</span>. But in researching this, I've also been drawn to what makes us human, and what distinguishes us from the machines we have built – ironically – <span class="highlight">to mimic us</span>.</p>

								<p>We are <span class="highlight">organic, emotive, embodied beings</span>. We need the earth, the moon, the weather, gravity, to define our existence. Communication, therefore, is essentially a <span class="highlight">physical transaction</span> – one that often bypasses language altogether. Our bodies communicate almost immediately, revealing our true being. They are <span class="highlight">honest portals</span> through which we interact with one another.</p>

								<p>As Turkle's research highlights, the <span class="highlight">digital world is not necessarily a truthful one</span>. Online, we learn to become actors, taking on different roles and re-enacting them for whoever will like our comments and <span class="highlight">reinforce our performance</span>.</p>

								<p>I have found myself wondering why, sadly, I haven't felt compelled to ring or truly interact with a friend who recently moved far far away. It isn't a feeling of annoyance, but of <span class="highlight">letting go</span>. Like tides coming in and out, people arrive and depart. Perhaps we have to allow this – to let them go, and allow them to build new relationships and new lives that are true to their <span class="highlight">embodied being</span>.</p>
							</div>
						</details>
					</div>
				</div>
			</section>
		</main>

		<footer>
			<a href="#top" class="btn">Back to top</a>
		</footer>
	</div>
</body>
</html>