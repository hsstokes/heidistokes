<!DOCTYPE html>
<html lang="en">
	<head>
	   <meta charset="UTF-8">
	   <meta name="viewport"
	   content="width=device-width,initial-scale=1.0">
	   <link rel="stylesheet" href="css/styles.css">
	<title>DEVELOPING THE LANGUAGE OF THE MULTIMODAL GRAPH</title>
   </head>
	<body id="top">
		<div class="page-wrapper">
		<div class="page-container">
			<header>
				<h1>DEVELOPING THE LANGUAGE OF THE MULTIMODAL GRAPH</h1>
		   </header>
		   
		   <main>
		   
		   <div class="section-content">
			 <p class="subtitle">Developing the Multimodal Graph <b>– ‘Data-Driven Engine’</b></p>
			<p class="description"><i>This outcome focuses on the development of a visual language for AI’s emotional interpretation. Using the concept of a ‘Data-Driven Engine,’ it highlights how AI uses data to process and map emotions, blending auditory and visual elements to represent this process.”</i>
			   </p>
		   </div>
		   
		   <section id="visuals">
		   <h2>Visual Outcomes</h2>
			<figure class="image-container">
			 <img src="images/visual-1.jpg" alt="Speech prosody /time, rhythm, timbres of speech">
		  <figcaption>Speech prosody /time, rhythm, timbres of speech</figcaption>
			</figure>
			
			
			<figure class="image-container">
			 <img src="images/visual-2.jpg" alt="Language/ emotion analysis Data driven engine">
		  <figcaption>Language/ emotion analysis "Data driven engine"</figcaption>
		   </figure>
		   
		   			
			<figure class="image-container">
			 <img src="images/visual-3.jpg" alt="visual research">
		  <figcaption>Visual research</figcaption>
		   </figure>
		   
		   				<h3>Tools used to Visually interpret AI's Emotional Comprehension</h3>

				<ol>
					<li><b>Hume AI: </b>Analysing speech prosody to detect emotions in language.</li>
				  <br />
					<li><b>Poe: </b>Interpreting emotions through shapes.</li>
				  <br />
					<li><b>Stable Audio: </b>Translating emotional tones into sound.</li>
				  <br />
					<li><b>AI Generative Tools: </b>Exploring hand gesture interpretations through various AI models.</li>
				  <br />
				</ol>
		   
		   
		   <div class="section-content">
			 <p class="subtitle">Future Exploration</p>
			<p class="description"><i>At this stage, I was really keen on creating something that looked more scientific—a graph that would clearly map each emotion to its corresponding hand gesture. But I was still frustrated with the projection mapping. I wanted to keep some animation in the mix, so I decided to animate each of the hand gestures, as if they were part of a diagram in a digital world. The result was a bit eerie, but also fascinating.

I started imagining how this could work in a digital space—what if a sound triggered when you swiped a still hand, and it came to life in animation? That would add a whole new level of interactivity. But honestly, my coding skills were pretty minimal at that point, and it felt too complex to pull off. So, I decided to take a step back, keep it simple, and focus on sketchbooks, film outcomes, and the touchboard with sound effects.”</i>
			   </p>
		   </div>
		  </section>

		  </main>
	
			<hr class="dotted-divider">
			
		<footer>
			<p id="contact">Contact me at: <a href="mailto:heidistokes2001@yahoo.co.uk">heidistokes2001@yahoo.co.uk</a></p>
			<p><a href="#top">Back to top</a></p>
		</footer>
	   </div>
	   </div>
	</body>
</html>
